name: benchmarks
on:
  workflow_call:
    inputs:
      publish:
        required: true
        type: boolean
      test-flags:
        required: true
        type: string

env:
  CGO_ENABLED: 0

jobs:
  benchmarks:
    if: ${{ github.repository == 'sw360cab/gno' }}
    runs-on: [self-hosted, Linux, X64, benchmarks]
    steps:
    - name: checkout
      uses: actions/checkout@v4
      with:
        fetch-depth: 1
    
    - uses: actions/setup-go@v5
      with:
        go-version: "1.22.x"

    - name: Run benchmark
      run: go test -benchmem -bench=. -run=^$ github.com/gnolang/gno/ -cpu 1,2 ${{ inputs.test-flags }} | tee benchmarks.txt

    - name: Download previous benchmark data
      uses: actions/cache@v4
      with:
        path: ./cache
        key: ${{ runner.os }}-benchmark
    
    - name: Store benchmark result - separate results repo
      uses: benchmark-action/github-action-benchmark@v1
      # see https://github.com/benchmark-action/github-action-benchmark?tab=readme-ov-file#action-inputs
      with:
        ### TODO: change
        name: Go Benchmarks
        tool: 'go'
        output-file-path: benchmarks.txt
        # Where the previous data file is stored
        external-data-json-path: ./cache/benchmark-data.json
        github-token: ${{ secrets.GITHUB_TOKEN }}
        # Show alert with commit comment on detecting possible performance regression
        alert-threshold: '150%'
        fail-on-alert: true
        comment-on-alert: true
        # Enable Job Summary for PRs
        summary-always: true
        ### gh-repository: 'github.com/gnolang/benchmarks' # on gh-pages branch
        auto-push: ${{ inputs.publish }}
        ### alert-comment-cc-users: '@ajnavarro'
