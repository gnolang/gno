--- interface.go.orig	2025-02-27 18:57:18.000000000 +0100
+++ interface.go	2025-03-28 09:37:22.300906508 +0100
@@ -95,6 +95,7 @@
 	file := fset.AddFile(filename, -1, len(text))
 
 	var p parser
+	p.maxNest = maxNestLev
 	defer func() {
 		if e := recover(); e != nil {
 			// resume same panic if it's not a bailout
@@ -127,12 +128,70 @@
 	}()
 
 	// parse source
-	p.init(file, text, mode)
+	p.init(file, text, mode, 0)
 	f = p.parseFile()
 
 	return
 }
 
+type Stats struct {
+	TopNest int
+	NumTok  int
+}
+
+func ParseFileStats(fset *token.FileSet, filename string, src any, mode Mode, maxNest int) (f *ast.File, s *Stats, err error) {
+	if fset == nil {
+		panic("parser.ParseFile: no token.FileSet provided (fset == nil)")
+	}
+
+	// get source
+	text, err := readSource(filename, src)
+	if err != nil {
+		return nil, nil, err
+	}
+
+	file := fset.AddFile(filename, -1, len(text))
+
+	var p parser
+	defer func() {
+		if e := recover(); e != nil {
+			// resume same panic if it's not a bailout
+			bail, ok := e.(bailout)
+			if !ok {
+				panic(e)
+			} else if bail.msg != "" {
+				p.errors.Add(p.file.Position(bail.pos), bail.msg)
+			}
+		}
+
+		// set result values
+		if f == nil {
+			// source is not a valid Go source file - satisfy
+			// ParseFile API and return a valid (but) empty
+			// *ast.File
+			f = &ast.File{
+				Name:  new(ast.Ident),
+				Scope: ast.NewScope(nil),
+			}
+		}
+
+		// Ensure the start/end are consistent,
+		// whether parsing succeeded or not.
+		f.FileStart = token.Pos(file.Base())
+		f.FileEnd = token.Pos(file.Base() + file.Size())
+
+		p.errors.Sort()
+		err = p.errors.Err()
+	}()
+
+	// parse source
+	p.init(file, text, mode, maxNest)
+	f = p.parseFile()
+	s = &Stats{p.topNest, p.numTok}
+
+	return
+}
+
 // ParseDir calls [ParseFile] for all files with names ending in ".go" in the
 // directory specified by path and returns a map of package name -> package
 // AST with all the packages found.
@@ -223,7 +282,7 @@
 
 	// parse expr
 	file := fset.AddFile(filename, -1, len(text))
-	p.init(file, text, mode)
+	p.init(file, text, mode, 0)
 	expr = p.parseRhs()
 
 	// If a semicolon was inserted, consume it;
@@ -236,6 +295,49 @@
 	return
 }
 
+func ParseExprFromStats(fset *token.FileSet, filename string, src any, mode Mode, maxNest int) (expr ast.Expr, s *Stats, err error) {
+	if fset == nil {
+		panic("parser.ParseExprFrom: no token.FileSet provided (fset == nil)")
+	}
+
+	// get source
+	text, err := readSource(filename, src)
+	if err != nil {
+		return nil, nil, err
+	}
+
+	var p parser
+	defer func() {
+		if e := recover(); e != nil {
+			// resume same panic if it's not a bailout
+			bail, ok := e.(bailout)
+			if !ok {
+				panic(e)
+			} else if bail.msg != "" {
+				p.errors.Add(p.file.Position(bail.pos), bail.msg)
+			}
+		}
+		p.errors.Sort()
+		err = p.errors.Err()
+	}()
+
+	// parse expr
+	file := fset.AddFile(filename, -1, len(text))
+	p.init(file, text, mode, maxNest)
+	expr = p.parseRhs()
+
+	// If a semicolon was inserted, consume it;
+	// report an error if there's more tokens.
+	if p.tok == token.SEMICOLON && p.lit == "\n" {
+		p.next()
+	}
+	p.expect(token.EOF)
+
+	s = &Stats{p.topNest, p.numTok}
+
+	return
+}
+
 // ParseExpr is a convenience function for obtaining the AST of an expression x.
 // The position information recorded in the AST is undefined. The filename used
 // in error messages is the empty string.
@@ -246,3 +348,7 @@
 func ParseExpr(x string) (ast.Expr, error) {
 	return ParseExprFrom(token.NewFileSet(), "", []byte(x), 0)
 }
+
+func ParseExprStats(x string, maxNest int) (ast.Expr, *Stats, error) {
+	return ParseExprFromStats(token.NewFileSet(), "", []byte(x), 0, maxNest)
+}
--- parser.go.orig	2025-02-27 18:57:18.000000000 +0100
+++ parser.go	2025-03-27 10:01:09.585754556 +0100
@@ -63,13 +63,26 @@
 	// nestLev is used to track and limit the recursion depth
 	// during parsing.
 	nestLev int
+
+	// maxNest is the maximum nesting level authorized for this parser.
+	maxNest int
+
+	// topNest is the maximum nesting level reached durin parsing.
+	topNest int
+
+	// numTok is the number of parsed tokens.
+	numTok int
 }
 
-func (p *parser) init(file *token.File, src []byte, mode Mode) {
+func (p *parser) init(file *token.File, src []byte, mode Mode, maxNest int) {
 	p.file = file
 	eh := func(pos token.Position, msg string) { p.errors.Add(pos, msg) }
 	p.scanner.Init(p.file, src, eh, scanner.ScanComments)
 
+	p.maxNest = maxNest
+	if p.maxNest == 0 {
+		p.maxNest = maxNestLev
+	}
 	p.top = true
 	p.mode = mode
 	p.trace = mode&Trace != 0 // for convenience (p.trace is used frequently)
@@ -111,10 +124,13 @@
 
 func incNestLev(p *parser) *parser {
 	p.nestLev++
-	if p.nestLev > maxNestLev {
-		p.error(p.pos, "exceeded max nesting depth")
+	if p.nestLev > p.maxNest {
+		p.error(p.pos, fmt.Sprintf("exceeded max nesting depth %d", p.maxNest))
 		panic(bailout{})
 	}
+	if p.topNest < p.nestLev {
+		p.topNest = p.nestLev
+	}
 	return p
 }
 
@@ -144,6 +160,7 @@
 
 	for {
 		p.pos, p.tok, p.lit = p.scanner.Scan()
+		p.numTok++
 		if p.tok == token.COMMENT {
 			if p.top && strings.HasPrefix(p.lit, "//go:build") {
 				if x, err := constraint.Parse(p.lit); err == nil {
